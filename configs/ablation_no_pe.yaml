# Ablation Study: Without Positional Encoding
model_type: 'encoder'
device: 'cpu'

model:
  d_model: 64
  nhead: 4
  num_encoder_layers: 2
  num_decoder_layers: 2
  dim_feedforward: 256
  dropout: 0.1
  use_positional_encoding: false

data:
  max_length: 32
  batch_size: 32
  vocab_size: 10000

training:
  epochs: 10
  learning_rate: 0.0001
  warmup_steps: 4000

paths:
  model_save_path: "models/ablation_no_pe.pth"
  result_save_path: "results/ablation_no_pe.txt"
  plot_save_path: "results/ablation_no_pe.png"